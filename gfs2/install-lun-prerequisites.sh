#!/bin/bash

# ============================================================================
# SCRIPT: install-lun-prerequisites.sh
# DESCRI√á√ÉO: Instala√ß√£o e configura√ß√£o de pr√©-requisitos para GFS2 Enterprise
# VERS√ÉO: 2.0 - Enterprise Cluster Ready
# AUTOR: DevOps Team
# ============================================================================

# Configura√ß√µes globais
set -euo pipefail

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Vari√°veis do cluster
readonly CLUSTER_NAME="cluster_gfs2"
readonly NODE1_IP="192.168.0.252"
readonly NODE2_IP="192.168.0.251"
readonly NODE1_NAME="fc-test1"
readonly NODE2_NAME="fc-test2"

# ============================================================================
# FUN√á√ïES AUXILIARES
# ============================================================================

print_header() {
    echo -e "\n${BLUE}========================================================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}========================================================================${NC}\n"
}

print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_info() {
    echo -e "${BLUE}‚ÑπÔ∏è  $1${NC}"
}

error_exit() {
    print_error "$1"
    exit 1
}

# ============================================================================
# DETEC√á√ÉO DE AMBIENTE E N√ì
# ============================================================================

detect_node_role() {
    local current_ip
    current_ip=$(ip route get 8.8.8.8 2>/dev/null | awk '/src/ {print $7}' || echo "unknown")
    
    if [[ "$current_ip" == "$NODE1_IP" ]]; then
        echo "primary"
    elif [[ "$current_ip" == "$NODE2_IP" ]]; then
        echo "secondary"
    else
        echo "unknown"
    fi
}

get_current_hostname() {
    hostname -s
}

# ============================================================================
# VERIFICA√á√ïES PR√â-REQUISITOS
# ============================================================================

check_prerequisites() {
    print_header "üîç Verificando Pr√©-requisitos do Sistema"
    
    # Verificar se √© executado como root
    if [[ $EUID -eq 0 ]]; then
        print_warning "Script executado como root. Recomendado usar sudo."
    fi
    
    # Verificar conectividade de rede
    local other_node
    if [[ "$(detect_node_role)" == "primary" ]]; then
        other_node="$NODE2_NAME"
    else
        other_node="$NODE1_NAME"
    fi
    
    if ! ping -c 2 "$other_node" &>/dev/null; then
        print_error "N√£o foi poss√≠vel conectar com $other_node"
        print_info "Verifique conectividade de rede entre os n√≥s"
        return 1
    fi
    
    print_success "Conectividade com $other_node verificada"
    
    # Verificar resolu√ß√£o DNS
    if ! nslookup "$other_node" &>/dev/null; then
        print_warning "Resolu√ß√£o DNS pode estar comprometida"
        print_info "Verificar entradas em /etc/hosts"
    fi
    
    # Verificar espa√ßo em disco
    local available_space
    available_space=$(df / | tail -1 | awk '{print $4}')
    if [[ $available_space -lt 1000000 ]]; then
        print_warning "Pouco espa√ßo em disco dispon√≠vel: ${available_space}KB"
    fi
    
    print_success "Pr√©-requisitos b√°sicos verificados"
    return 0
}

# ============================================================================
# INSTALA√á√ÉO DE PACOTES
# ============================================================================

install_packages() {
    print_header "üì¶ Instalando Pacotes Necess√°rios"
    
    # Atualizar reposit√≥rios
    print_info "Atualizando reposit√≥rios..."
    sudo apt update -qq
    
    # Lista de pacotes essenciais
    local packages=(
        "gfs2-utils"
        "corosync"
        "pacemaker"
        "pcs"
        "dlm-controld"
        "lvm2-lockd"
        "multipath-tools"
        "open-iscsi"
        "fence-agents"
        "resource-agents"
    )
    
    print_info "Instalando pacotes GFS2 e Cluster..."
    for package in "${packages[@]}"; do
        if dpkg -l | grep -q "^ii  $package "; then
            print_success "$package j√° instalado"
        else
            print_info "Instalando $package..."
            if sudo apt install -y "$package" &>/dev/null; then
                print_success "$package instalado com sucesso"
            else
                print_error "Falha ao instalar $package"
                return 1
            fi
        fi
    done
    
    # Configurar senha do hacluster se necess√°rio
    if ! sudo passwd -S hacluster 2>/dev/null | grep -q "hacluster P"; then
        print_info "Configurando senha do usu√°rio hacluster..."
        echo 'hacluster:hacluster' | sudo chpasswd
        print_success "Senha do hacluster configurada"
    fi
    
    print_success "Todos os pacotes instalados com sucesso"
    return 0
}

# ============================================================================
# CONFIGURA√á√ÉO DE CLUSTER ENTERPRISE
# ============================================================================
# 
# STONITH (Shoot The Other Node In The Head):
#   - PRODU√á√ÉO: Obrigat√≥rio para isolamento de n√≥s com falha
#   - LABORAT√ìRIO: Desabilitado (sem dispositivos de fencing)
#   - STAGING: Opcional dependendo da infraestrutura
#
# NO-QUORUM-POLICY:
#   - PRODU√á√ÉO: 'stop' ou 'freeze' (para em caso de perda de quorum)
#   - LABORAT√ìRIO: 'ignore' (continua operando para testes)
#   - DOIS N√ìS: Sempre 'ignore' (qualquer falha causa perda de quorum)
#
# REFER√äNCIAS:
#   - Red Hat HA-Cluster: https://access.redhat.com/documentation/
#   - Pacemaker Documentation: https://clusterlabs.org/pacemaker/doc/
# ============================================================================

configure_cluster_properties() {
    print_info "Configurando propriedades do cluster..."
    
    # Configura√ß√µes essenciais para laborat√≥rio/desenvolvimento
    print_info "üìã Aplicando configura√ß√µes para ambiente de laborat√≥rio..."
    
    # STONITH - Desabilitar para laborat√≥rio (sem dispositivos de fencing)
    if sudo pcs property set stonith-enabled=false; then
        print_success "STONITH desabilitado (adequado para laborat√≥rio)"
    else
        print_warning "Falha ao desabilitar STONITH"
        return 1
    fi
    
    # Quorum Policy - Ignorar para clusters de 2 n√≥s
    if sudo pcs property set no-quorum-policy=ignore; then
        print_success "Pol√≠tica de quorum configurada para 2 n√≥s"
    else
        print_warning "Falha ao configurar pol√≠tica de quorum"
        return 1
    fi
    
    # Configura√ß√µes adicionais de robustez
    sudo pcs property set start-failure-is-fatal=false    # N√£o para cluster por falhas
    sudo pcs property set symmetric-cluster=true          # Recursos podem rodar em qualquer n√≥
    sudo pcs property set maintenance-mode=false          # Garantir modo operacional
    sudo pcs property set enable-startup-probes=true      # Verifica√ß√µes de inicializa√ß√£o
    
    print_success "Propriedades do cluster configuradas com sucesso"
    
    # Verificar configura√ß√µes aplicadas
    echo ""
    print_info "üìä Propriedades atuais do cluster:"
    sudo pcs property show | grep -E "(stonith-enabled|no-quorum-policy|start-failure-is-fatal)" || true
    
    return 0
}

configure_cluster_resources() {
    print_info "Configurando recursos DLM e lvmlockd..."
    
    # Aguardar cluster estabilizar
    sleep 15
    
    # Configurar recurso DLM
    if ! sudo pcs resource show dlm-clone &>/dev/null; then
        print_info "üîí Criando recurso DLM..."
        if sudo pcs resource create dlm systemd:dlm \
            op monitor interval=60s on-fail=fence \
            clone interleave=true ordered=true; then
            print_success "Recurso DLM criado"
        else
            print_error "Falha ao criar recurso DLM"
            return 1
        fi
    else
        print_success "Recurso DLM j√° existe"
    fi
    
    # Configurar recurso lvmlockd
    if ! sudo pcs resource show lvmlockd-clone &>/dev/null; then
        print_info "üíæ Criando recurso lvmlockd..."
        if sudo pcs resource create lvmlockd systemd:lvmlockd \
            op monitor interval=60s on-fail=fence \
            clone interleave=true ordered=true; then
            print_success "Recurso lvmlockd criado"
        else
            print_error "Falha ao criar recurso lvmlockd"
            return 1
        fi
    else
        print_success "Recurso lvmlockd j√° existe"
    fi
    
    # Configurar depend√™ncias entre recursos
    print_info "üîó Configurando depend√™ncias de recursos..."
    sudo pcs constraint order start dlm-clone then lvmlockd-clone 2>/dev/null || true
    sudo pcs constraint colocation add lvmlockd-clone with dlm-clone 2>/dev/null || true
    
    print_success "Recursos configurados com sucesso"
    
    # Aguardar recursos ficarem ativos
    print_info "‚è≥ Aguardando recursos ficarem ativos (60s)..."
    sleep 60
    
    return 0
}

configure_enterprise_cluster() {
    print_header "üè¢ Configurando Cluster Enterprise (Pacemaker/Corosync + DLM)"
    
    local node_role
    node_role=$(detect_node_role)
    
    case "$node_role" in
        "primary")
            print_info "üéØ Detectado como n√≥ PRIM√ÅRIO ($NODE1_NAME): $NODE1_IP"
            ;;
        "secondary")
            print_info "üéØ Detectado como n√≥ SECUND√ÅRIO ($NODE2_NAME): $NODE2_IP"
            ;;
        *)
            print_error "N√£o foi poss√≠vel detectar o papel do n√≥"
            print_info "IPs esperados: $NODE1_IP (prim√°rio) ou $NODE2_IP (secund√°rio)"
            return 1
            ;;
    esac
    
    # Verificar se cluster j√° existe
    if sudo pcs status &>/dev/null; then
        print_warning "Cluster j√° configurado. Verificando status..."
        sudo pcs status
        return 0
    fi
    
    # Configurar apenas no n√≥ prim√°rio
    if [[ "$node_role" == "primary" ]]; then
        print_info "üîß Configurando cluster no n√≥ prim√°rio..."
        
        # Garantir que pcsd est√° ativo em ambos os n√≥s
        sudo systemctl start pcsd
        sudo systemctl enable pcsd
        
        print_info "Verificando pcsd no n√≥ secund√°rio..."
        if ssh "$NODE2_NAME" "sudo systemctl start pcsd && sudo systemctl enable pcsd" 2>/dev/null; then
            print_success "pcsd ativo em ambos os n√≥s"
        else
            print_error "N√£o foi poss√≠vel iniciar pcsd no $NODE2_NAME"
            return 1
        fi
        
        # Aguardar pcsd estabilizar
        sleep 10
        
        # Autenticar n√≥s
        print_info "üîê Autenticando n√≥s do cluster..."
        if echo "hacluster" | sudo pcs host auth "$NODE1_NAME" "$NODE2_NAME" -u hacluster; then
            print_success "N√≥s autenticados com sucesso"
        else
            print_error "Falha na autentica√ß√£o dos n√≥s"
            print_info "üí° Verifique se a senha do hacluster est√° igual em ambos os n√≥s"
            return 1
        fi
        
        # Criar cluster com IPs espec√≠ficos
        print_info "üèóÔ∏è  Criando cluster com IPs reais..."
        if sudo pcs cluster setup "$CLUSTER_NAME" \
            "$NODE1_NAME" addr="$NODE1_IP" \
            "$NODE2_NAME" addr="$NODE2_IP"; then
            print_success "Cluster criado com sucesso"
        else
            print_error "Falha ao criar cluster"
            return 1
        fi
        
        # Iniciar cluster
        print_info "‚ñ∂Ô∏è  Iniciando cluster..."
        sudo pcs cluster start --all
        sudo pcs cluster enable --all
        
        # Aguardar cluster estabilizar
        print_info "‚è≥ Aguardando cluster estabilizar (30s)..."
        sleep 30
        
        # Configurar propriedades do cluster
        if ! configure_cluster_properties; then
            print_error "Falha ao configurar propriedades do cluster"
            return 1
        fi
        
        # Configurar recursos do cluster
        if ! configure_cluster_resources; then
            print_error "Falha ao configurar recursos do cluster"
            return 1
        fi
        
        # Verificar status final
        echo ""
        print_info "üìä Status final do cluster:"
        sudo pcs status
        
        # Validar configura√ß√£o
        if validate_cluster_configuration; then
            print_success "Cluster configurado com sucesso!"
            print_success "Ambos os n√≥s est√£o online"
            print_success "Recursos DLM e lvmlockd ativos"
        else
            print_warning "Cluster criado mas verificar status dos n√≥s"
            return 1
        fi
        
    else
        print_info "‚è≥ Aguardando configura√ß√£o do cluster pelo n√≥ prim√°rio..."
        
        # Aguardar cluster ser configurado pelo n√≥ prim√°rio
        local timeout=180
        local count=0
        while ! sudo pcs status &>/dev/null && [[ $count -lt $timeout ]]; do
            echo "   Aguardando cluster... ($count/${timeout}s)"
            sleep 10
            ((count+=10))
        done
        
        if sudo pcs status &>/dev/null; then
            print_success "Cluster detectado! Verificando participa√ß√£o..."
            sudo pcs status
        else
            print_error "Timeout: Cluster n√£o foi detectado ap√≥s ${timeout}s"
            return 1
        fi
    fi
    
    return 0
}

validate_cluster_configuration() {
    print_info "üîç Validando configura√ß√£o do cluster..."
    
    # Verificar STONITH
    local stonith_status
    stonith_status=$(sudo pcs property show stonith-enabled 2>/dev/null | awk '/stonith-enabled/ {print $2}' || echo "unknown")
    if [[ "$stonith_status" == "false" ]]; then
        print_success "STONITH adequadamente desabilitado para laborat√≥rio"
    else
        print_warning "STONITH habilitado - verificar dispositivos de fencing"
    fi
    
    # Verificar Quorum Policy
    local quorum_policy
    quorum_policy=$(sudo pcs property show no-quorum-policy 2>/dev/null | awk '/no-quorum-policy/ {print $2}' || echo "unknown")
    if [[ "$quorum_policy" == "ignore" ]]; then
        print_success "Pol√≠tica de quorum adequada para cluster de 2 n√≥s"
    else
        print_warning "Pol√≠tica de quorum pode causar problemas em cluster de 2 n√≥s"
    fi
    
    # Verificar se ambos os n√≥s est√£o online
    if sudo pcs status | grep -q "Online:.*$NODE1_NAME.*$NODE2_NAME" || sudo pcs status | grep -q "Online:.*$NODE2_NAME.*$NODE1_NAME"; then
        print_success "Ambos os n√≥s est√£o online"
        return 0
    else
        print_error "Nem todos os n√≥s est√£o online"
        return 1
    fi
}

# ============================================================================
# CONFIGURA√á√ÉO DE STORAGE LVM
# ============================================================================

detect_available_devices() {
    print_header "üíæ Detectando Devices de Storage Dispon√≠veis"
    
    local devices=()
    local processed_devices=()
    
    # Fun√ß√£o auxiliar para verificar e adicionar device
    check_and_add_device() {
        local device="$1"
        local type="$2"
        local real_device
        
        print_info "Tentando adicionar device: $device (tipo: $type)"
        
        # Resolver link simb√≥lico para o device real
        real_device=$(readlink -f "$device")
        print_info "Device real: $real_device"
        
        # Verificar se j√° processamos este device
        for processed in "${processed_devices[@]}"; do
            if [[ "$processed" == "$real_device" ]]; then
                print_info "Device j√° processado anteriormente: $real_device"
                return 0
            fi
        done
        processed_devices+=("$real_device")
        
        # Debug: mostrar device sendo processado
        print_info "Verificando device: $device (real: $real_device)"
        
        if [[ -b "$device" ]]; then
            local size
            size=$(lsblk -dn -o SIZE "$device" 2>/dev/null || echo "N/A")
            local wwn
            wwn=$(lsblk -dn -o WWN "$device" 2>/dev/null || echo "N/A")
            local dm_name
            dm_name=$(readlink -f "$device" 2>/dev/null | xargs basename 2>/dev/null || echo "unknown")
            local mountpoint
            mountpoint=$(lsblk -dn -o MOUNTPOINT "$device" 2>/dev/null || echo "")
            local vendor
            vendor=$(lsblk -dn -o VENDOR "$device" 2>/dev/null | tr -d ' ' || echo "N/A")
            local model
            model=$(lsblk -dn -o MODEL "$device" 2>/dev/null | tr -d ' ' || echo "N/A")
            
            # Verificar se √© um device do sistema ou j√° est√° em uso
            print_info "Verificando device $device:"
            print_info "  - Mountpoint: '$mountpoint'"
            print_info "  - Size: $size"
            print_info "  - WWN: $wwn"
            print_info "  - Vendor: $vendor"
            print_info "  - Model: $model"
            
            # Verificar se √© um device do sistema ou j√° est√° em uso como PV
            local is_pv=false
            if pvs "$device" &>/dev/null; then
                is_pv=true
                print_warning "Device $device j√° em uso como Physical Volume"
            fi
            
            if [[ -z "$mountpoint" ]] && [[ "$is_pv" == "false" ]]; then
                local info="$device - Tamanho: $size"
                [[ "$wwn" != "N/A" ]] && info+=" - WWN: $wwn"
                [[ "$vendor" != "N/A" ]] && info+=" - Vendor: $vendor"
                [[ "$model" != "N/A" ]] && info+=" - Model: $model"
                [[ "$type" == "multipath" ]] && info+=" - DM: $dm_name"
                
                devices+=("$info")
                print_success "‚úÖ Device $type adicionado: $info"
            else
                if [[ -n "$mountpoint" ]]; then
                    print_warning "Device $device montado em $mountpoint"
                fi
            fi
        fi
    }
    
    # Procurar por devices multipath
    print_info "Procurando devices multipath..."
    shopt -s nullglob
    
    # Debug: mostrar sa√≠da do comando multipath -ll
    print_info "Sa√≠da do multipath -ll:"
    sudo multipath -ll
    
    print_info "Conte√∫do do /dev/mapper:"
    ls -l /dev/mapper/
    
    print_info "Procurando devices multipath ativos..."
    
    # Primeiro, procurar o device espec√≠fico fc-lun-cluster
    if [[ -b "/dev/mapper/fc-lun-cluster" ]]; then
        print_info "üéØ Encontrado device fc-lun-cluster"
        check_and_add_device "/dev/mapper/fc-lun-cluster" "multipath"
    else
        print_warning "Device /dev/mapper/fc-lun-cluster n√£o encontrado como block device"
        
        # Tentar usando o device mapper diretamente
        if [[ -b "/dev/dm-0" ]]; then
            print_info "üîç Encontrado device /dev/dm-0"
            check_and_add_device "/dev/dm-0" "multipath"
        fi
    fi
    
    # Depois, procurar outros devices multipath
    local mpaths
    mpaths=$(sudo multipath -l)
    print_info "Sa√≠da completa do multipath -l:"
    echo "$mpaths"
    
    while IFS= read -r line; do
        # Debug da linha atual
        print_info "Processando linha: $line"
        
        if [[ $line =~ ^([[:alnum:]_-]+)[[:space:]] ]]; then
            local mp_name="${BASH_REMATCH[1]}"
            local mp_device="/dev/mapper/$mp_name"
            
            print_info "Encontrado nome multipath: $mp_name"
            print_info "Verificando device: $mp_device"
            
            if [[ -b "$mp_device" ]]; then
                print_info "Encontrado device multipath ativo: $mp_device"
                check_and_add_device "$mp_device" "multipath"
            else
                print_info "Device $mp_device n√£o existe como block device"
            fi
        fi
    done < <(echo "$mpaths" | grep "^[[:alnum:]_-]" || true)
    
    # Procurar por LUNs em /dev/disk/by-id (especialmente wwn e scsi)
    print_info "Procurando LUNs por WWN e SCSI ID..."
    for device in /dev/disk/by-id/wwn-* /dev/disk/by-id/scsi-*; do
        check_and_add_device "$device" "wwn/scsi"
    done
    
    # Procurar por LUNs em /dev/disk/by-path
    print_info "Procurando LUNs por path..."
    for device in /dev/disk/by-path/*; do
        if [[ "$device" =~ -lun- ]]; then
            check_and_add_device "$device" "path"
        fi
    done
    
    # Procurar por devices f√≠sicos adequados (excluir disco do sistema)
    print_info "Procurando devices f√≠sicos..."
    for device in /dev/sd[b-z]; do
        check_and_add_device "$device" "physical"
    done
    
    if [[ ${#devices[@]} -eq 0 ]]; then
        print_error "Nenhum device dispon√≠vel encontrado"
        return 1
    fi
    
    # Debug: mostrar todos os devices encontrados
    print_info "Devices candidatos detectados:"
    for i in "${!devices[@]}"; do
        echo "$((i + 1)). ${devices[i]}"
    done
    
    # Selecionar device automaticamente ou manualmente
    local selected_device
    if [[ ${#devices[@]} -eq 1 ]]; then
        selected_device=$(echo "${devices[0]}" | awk '{print $1}')
        print_info "Selecionando automaticamente √∫nico device: $selected_device"
    else
        echo ""
        read -p "Selecione o device para criar VG compartilhado (n√∫mero): " choice
        if [[ "$choice" =~ ^[0-9]+$ ]] && [[ "$choice" -ge 1 ]] && [[ "$choice" -le ${#devices[@]} ]]; then
            selected_device=$(echo "${devices[$((choice - 1))]}" | awk '{print $1}')
            print_info "Device selecionado: $selected_device"
        else
            print_error "Sele√ß√£o inv√°lida"
            return 1
        fi
    fi
    
    echo "$selected_device"
    return 0
}

configure_lvm_cluster() {
    print_header "‚öôÔ∏è  Configurando LVM para Cluster"
    
    # Detectar device dispon√≠vel
    local selected_device
    if ! selected_device=$(detect_available_devices); then
        print_error "Falha na detec√ß√£o de devices"
        return 1
    fi
    
    # Configurar LVM para cluster
    print_info "Configurando LVM para uso em cluster..."
    
    # Verificar se lvm.conf est√° configurado para cluster
    if ! grep -q "use_lvmlockd = 1" /etc/lvm/lvm.conf 2>/dev/null; then
        print_info "Configurando /etc/lvm/lvm.conf para cluster..."
        sudo sed -i 's/use_lvmlockd = 0/use_lvmlockd = 1/' /etc/lvm/lvm.conf 2>/dev/null || true
        sudo sed -i 's/# use_lvmlockd = 1/use_lvmlockd = 1/' /etc/lvm/lvm.conf 2>/dev/null || true
        
        # Se n√£o encontrou a linha, adicionar
        if ! grep -q "use_lvmlockd" /etc/lvm/lvm.conf; then
            sudo sed -i '/global {/a\    use_lvmlockd = 1' /etc/lvm/lvm.conf
        fi
        
        print_success "LVM configurado para cluster"
    else
        print_success "LVM j√° configurado para cluster"
    fi
    
    # Verificar se Volume Group j√° existe
    local vg_name="vg_cluster"
    local lv_name="lv_gfs2"
    
    if sudo vgs "$vg_name" &>/dev/null; then
        print_info "Volume Group '$vg_name' j√° existe"
        
        # Verificar se est√° em modo cluster
        local lock_type
        lock_type=$(sudo vgs --noheadings -o lv_lock_type "$vg_name" 2>/dev/null | tr -d ' ' || echo "none")
        
        if [[ "$lock_type" != "dlm" ]]; then
            print_info "Convertendo Volume Group para modo cluster DLM..."
            
            # Parar locks se existirem
            sudo vgchange --lockstop "$vg_name" 2>/dev/null || true
            
            # Converter para DLM
            if sudo vgchange --locktype dlm "$vg_name"; then
                print_success "Volume Group convertido para modo cluster"
            else
                print_error "Falha ao converter Volume Group para modo cluster"
                return 1
            fi
        fi
        
        # Iniciar locks
        if sudo vgchange --lockstart "$vg_name"; then
            print_success "Locks do Volume Group iniciados"
        else
            print_warning "Falha ao iniciar locks - continuando sem locks distribu√≠dos"
            # Converter para modo local como fallback
            sudo vgchange --locktype none "$vg_name" 2>/dev/null || true
        fi
        
        # Ativar Volume Group
        if sudo vgchange -ay "$vg_name"; then
            print_success "Volume Group ativado"
        else
            print_error "Falha ao ativar Volume Group"
            return 1
        fi
        
    else
        print_info "Criando novo Volume Group cluster-aware..."
        
        local device_size
        device_size=$(lsblk -dn -o SIZE "$selected_device" | tr -d ' ')
        print_info "Device selecionado: $selected_device"
        print_info "Tamanho total do device: $device_size"
        print_info "Ser√° usado TODO o espa√ßo dispon√≠vel para m√°ximo aproveitamento."
        
        echo ""
        read -p "Criar VG '$vg_name' e LV '$lv_name' usando todo o espa√ßo no device $selected_device? [s/N]: " confirm
        if [[ "$confirm" != "s" && "$confirm" != "S" ]]; then
            print_info "Opera√ß√£o cancelada pelo usu√°rio"
            return 1
        fi
        
        # Criar Physical Volume
        if sudo pvcreate -y "$selected_device"; then
            print_success "Physical Volume criado: $selected_device"
        else
            print_error "Falha ao criar Physical Volume"
            return 1
        fi
        
        # Criar Volume Group cluster-aware
        if sudo vgcreate --shared "$vg_name" "$selected_device"; then
            print_success "Volume Group cluster-aware criado: $vg_name"
        else
            print_error "Falha ao criar Volume Group"
            return 1
        fi
        
        # Iniciar locks DLM se poss√≠vel
        if sudo vgchange --locktype dlm "$vg_name" && sudo vgchange --lockstart "$vg_name"; then
            print_success "Volume Group configurado com locks DLM"
        else
            print_warning "Falha ao configurar locks DLM - usando modo local"
            sudo vgchange --locktype none "$vg_name" 2>/dev/null || true
        fi
        
        # Ativar Volume Group
        sudo vgchange -ay "$vg_name"
        
        # Criar Logical Volume usando todo o espa√ßo
        if sudo lvcreate -l 100%FREE -n "$lv_name" "$vg_name"; then
            print_success "Logical Volume criado: /dev/$vg_name/$lv_name"
        else
            print_error "Falha ao criar Logical Volume"
            return 1
        fi
    fi
    
    # Verificar resultado final
    print_info "üìä Configura√ß√£o final do LVM:"
    sudo vgs "$vg_name" || true
    sudo lvs "$vg_name" || true
    
    print_success "Configura√ß√£o de LVM cluster conclu√≠da"
    return 0
}

# ============================================================================
# FUN√á√ÉO PRINCIPAL
# ============================================================================

main() {
    print_header "üöÄ Instala√ß√£o de Pr√©-requisitos GFS2 Enterprise"
    
    print_info "Iniciando configura√ß√£o para ambiente enterprise..."
    print_info "N√≥ atual: $(get_current_hostname)"
    print_info "IP detectado: $(ip route get 8.8.8.8 2>/dev/null | awk '/src/ {print $7}' || echo 'N/A')"
    
    # Verificar pr√©-requisitos
    if ! check_prerequisites; then
        error_exit "Falha na verifica√ß√£o de pr√©-requisitos"
    fi
    
    # Instalar pacotes necess√°rios
    if ! install_packages; then
        error_exit "Falha na instala√ß√£o de pacotes"
    fi
    
    # Configurar cluster enterprise
    if ! configure_enterprise_cluster; then
        print_error "Erro na configura√ß√£o do cluster"
        print_info "üí° Voc√™ pode continuar com configura√ß√£o local, mas perder√° recursos enterprise"
        read -p "Continuar com configura√ß√£o local (sem cluster)? [s/N]: " continue_local
        if [[ "$continue_local" == "s" || "$continue_local" == "S" ]]; then
            print_info "Prosseguindo com configura√ß√£o local..."
        else
            error_exit "Configura√ß√£o do cluster falhou"
        fi
    fi
    
    # Configurar storage LVM
    if ! configure_lvm_cluster; then
        error_exit "Falha na configura√ß√£o de storage LVM"
    fi
    
    # Relat√≥rio final
    print_header "‚úÖ Instala√ß√£o Conclu√≠da com Sucesso!"
    
    echo ""
    print_success "üè¢ Cluster Enterprise Configurado:"
    print_info "   ‚Ä¢ Pacemaker/Corosync: Ativo"
    print_info "   ‚Ä¢ DLM distribu√≠do: Configurado"
    print_info "   ‚Ä¢ lvmlockd cluster-aware: Ativo"
    print_info "   ‚Ä¢ Storage compartilhado: Pronto"
    
    echo ""
    print_success "üìã Pr√≥ximos Passos:"
    print_info "   1. Execute o mesmo script no outro n√≥"
    print_info "   2. Execute: configure-lun-multipath.sh (formata√ß√£o GFS2)"
    print_info "   3. Execute: configure-second-node.sh (montagem)"
    print_info "   4. Teste: test-lun-gfs2.sh (valida√ß√£o)"
    
    echo ""
    print_info "üìä Verifica√ß√£o do cluster:"
    sudo pcs status 2>/dev/null || print_warning "Use 'sudo pcs status' para verificar cluster"
    
    print_success "üéâ Ambiente enterprise pronto para GFS2!"
}

# ============================================================================
# EXECU√á√ÉO
# ============================================================================

# Verificar argumentos
case "${1:-}" in
    --help|-h)
        echo "Uso: $0 [op√ß√µes]"
        echo ""
        echo "Op√ß√µes:"
        echo "  --help, -h    Mostrar esta ajuda"
        echo "  --version     Mostrar vers√£o"
        echo ""
        echo "Este script configura um ambiente enterprise para GFS2 com:"
        echo "  ‚Ä¢ Cluster Pacemaker/Corosync"
        echo "  ‚Ä¢ DLM distribu√≠do"
        echo "  ‚Ä¢ lvmlockd cluster-aware"
        echo "  ‚Ä¢ Storage compartilhado"
        exit 0
        ;;
    --version)
        echo "install-lun-prerequisites.sh vers√£o 2.0 - Enterprise Ready"
        exit 0
        ;;
    "")
        # Execu√ß√£o normal
        main
        ;;
    *)
        error_exit "Argumento inv√°lido: $1. Use --help para ajuda."
        ;;
esac
